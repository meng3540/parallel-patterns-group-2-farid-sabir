This folder contains the initial CUDA implementation of a merge algorithm without any optimizations applied. It is intended as a baseline for comparison against future optimized versions. The implementation follows a parallel merge pattern using co-ranking, and assigns each thread a disjoint portion of the output array to compute.
The merge_kernel in this version calculates the co-rank boundaries for each thread based on its thread ID and merges the corresponding segments of two sorted input arrays A and B into a third array C. No shared memory or circular buffering is used in this version. All computation and data movement occurs in global memory.
The main file allocates memory for the input and output arrays, initializes sorted arrays A and B on the host, transfers them to the GPU, and then launches the kernel with 128 blocks and 256 threads per block. It then measures the execution time using the CPU clock and computes the effective memory bandwidth. Results are printed to the console.
Expected behavior includes correct merge of the arrays and performance in the range of 6 milliseconds execution time and approximately 4 GB/s of memory bandwidth, based on hardware.
